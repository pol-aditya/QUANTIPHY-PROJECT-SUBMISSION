{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec9774-d053-4115-9a7c-266f5a460787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1d975-bfeb-4d9d-a82e-1bb6a844fa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d8415e-21fa-4d56-80db-69370434ef0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0687fb02-38a4-4dd1-aaf2-2df1c5c2e635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\aditya\\anaconda3\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: selenium in c:\\users\\aditya\\anaconda3\\lib\\site-packages (4.38.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\aditya\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2025.10.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\aditya\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Upgrade pip safely inside Anaconda\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "\n",
    "# Required packages\n",
    "!{sys.executable} -m pip install selenium\n",
    "!{sys.executable} -m pip install webdriver-manager\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48004028-bb54-4998-993e-0af6c1061ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Loading BeMinimalist product page...\n",
      "üìÑ Scraping page 1...\n",
      "üìÑ Scraping page 2...\n",
      "üìÑ Scraping page 3...\n",
      "üìÑ Scraping page 4...\n",
      "üìÑ Scraping page 5...\n",
      "üìÑ Scraping page 6...\n",
      "üìÑ Scraping page 7...\n",
      "üìÑ Scraping page 8...\n",
      "üìÑ Scraping page 9...\n",
      "üìÑ Scraping page 10...\n",
      "üìÑ Scraping page 11...\n",
      "üìÑ Scraping page 12...\n",
      "üìÑ Scraping page 13...\n",
      "üìÑ Scraping page 14...\n",
      "üìÑ Scraping page 15...\n",
      "üìÑ Scraping page 16...\n",
      "üìÑ Scraping page 17...\n",
      "üìÑ Scraping page 18...\n",
      "üìÑ Scraping page 19...\n",
      "üìÑ Scraping page 20...\n",
      "üìÑ Scraping page 21...\n",
      "üìÑ Scraping page 22...\n",
      "üìÑ Scraping page 23...\n",
      "üìÑ Scraping page 24...\n",
      "üìÑ Scraping page 25...\n",
      "üìÑ Scraping page 26...\n",
      "üìÑ Scraping page 27...\n",
      "üìÑ Scraping page 28...\n",
      "üìÑ Scraping page 29...\n",
      "üìÑ Scraping page 30...\n",
      "üìÑ Scraping page 31...\n",
      "üìÑ Scraping page 32...\n",
      "üìÑ Scraping page 33...\n",
      "üìÑ Scraping page 34...\n",
      "üìÑ Scraping page 35...\n",
      "üìÑ Scraping page 36...\n",
      "üìÑ Scraping page 37...\n",
      "üìÑ Scraping page 38...\n",
      "üìÑ Scraping page 39...\n",
      "üìÑ Scraping page 40...\n",
      "üìÑ Scraping page 41...\n",
      "üìÑ Scraping page 42...\n",
      "üìÑ Scraping page 43...\n",
      "üìÑ Scraping page 44...\n",
      "üìÑ Scraping page 45...\n",
      "üìÑ Scraping page 46...\n",
      "üìÑ Scraping page 47...\n",
      "üìÑ Scraping page 48...\n",
      "üìÑ Scraping page 49...\n",
      "üìÑ Scraping page 50...\n",
      "\n",
      "üõë Stopped at page 51 (limit reached or end of pages).\n",
      "\n",
      "‚úÖ Extracted 250 total reviews.\n",
      "üíæ Saved as 'minimalist_reviews_alpha_arbutin_2.csv'\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# üßæ BeMinimalist Review Scraper ‚Äì Include Rating Column\n",
    "#   Product: Alpha Arbutin 2%\n",
    "# =========================================================\n",
    "\n",
    "# !pip install selenium beautifulsoup4 pandas webdriver-manager\n",
    "\n",
    "import os, time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import WebDriverException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ---------------- Setup Chrome ----------------\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless=new\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "# If Chrome binary exists locally, set it\n",
    "possible_paths = [\n",
    "    r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "    r\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "]\n",
    "for p in possible_paths:\n",
    "    if os.path.exists(p):\n",
    "        chrome_options.binary_location = p\n",
    "        break\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=ChromeService(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# ---------------- Target Product URL (Updated) ----------------\n",
    "url = \"https://beminimalist.co/collections/skin/products/alpha-arbutin-2\"\n",
    "\n",
    "print(\"üåê Loading BeMinimalist product page...\")\n",
    "driver.get(url)\n",
    "time.sleep(10)\n",
    "\n",
    "# Scroll to load reviews\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight * 0.6);\")\n",
    "time.sleep(5)\n",
    "\n",
    "# ---------------- Pagination Loop ----------------\n",
    "page = 1\n",
    "max_pages = 50\n",
    "collected_html = \"\"\n",
    "\n",
    "while page <= max_pages:\n",
    "    print(f\"üìÑ Scraping page {page}...\")\n",
    "    time.sleep(4)\n",
    "\n",
    "    collected_html += driver.page_source\n",
    "\n",
    "    try:\n",
    "        next_link = driver.find_element(By.CSS_SELECTOR, \"a[aria-label='Navigate to next page']\")\n",
    "        if next_link.get_attribute(\"aria-disabled\") == \"true\":\n",
    "            print(\"‚úÖ Reached last available page of reviews.\")\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_link)\n",
    "        time.sleep(2)\n",
    "        ActionChains(driver).move_to_element(next_link).click().perform()\n",
    "        page += 1\n",
    "        time.sleep(5)\n",
    "\n",
    "    except Exception:\n",
    "        print(\"‚úÖ No further 'Next' pagination link found ‚Äî finished.\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nüõë Stopped at page {page} (limit reached or end of pages).\")\n",
    "\n",
    "# ---------------- Parse All Reviews ----------------\n",
    "soup = BeautifulSoup(collected_html, \"html.parser\")\n",
    "review_blocks = soup.select(\"div.yotpo-review\")\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for i, r in enumerate(review_blocks, 1):\n",
    "    name = r.select_one(\".yotpo-reviewer-name\")\n",
    "    date = r.select_one(\".yotpo-review-date\")\n",
    "    rating_div = r.select_one(\".yotpo-star-rating.yotpo-review-star-rating\")\n",
    "    title = r.select_one(\".yotpo-review-title strong, .yotpo-review-title\")\n",
    "    text = r.select_one(\".yotpo-read-more-text, .content-review, .yotpo-review-content\")\n",
    "\n",
    "    rating_text = rating_div.get(\"aria-label\") if rating_div and rating_div.has_attr(\"aria-label\") else \"\"\n",
    "    rating = rating_text.split()[0] if rating_text else \"\"\n",
    "\n",
    "    reviews.append({\n",
    "        \"S.No\": i,\n",
    "        \"Name\": name.get_text(strip=True) if name else \"Anonymous\",\n",
    "        \"Date\": date.get_text(strip=True) if date else \"\",\n",
    "        \"Rating\": rating,\n",
    "        \"Title\": title.get_text(strip=True) if title else \"\",\n",
    "        \"Review\": text.get_text(strip=True) if text else \"\",\n",
    "    })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# ---------------- Save to CSV ----------------\n",
    "df = pd.DataFrame(reviews)\n",
    "df.to_csv(\"minimalist_reviews_alpha_arbutin_2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted {len(df)} total reviews.\")\n",
    "print(\"üíæ Saved as 'minimalist_reviews_alpha_arbutin_2.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a52e5dc8-d4d6-4d4f-a9af-95208b0a1032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extracted 250 total reviews.\n",
      "üíæ Saved as 'minimalist_reviews_alpha_arbutin_2.csv'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(reviews)\n",
    "df.to_csv(\"minimalist_reviews_alpha_arbutin_2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n‚úÖ Extracted {len(df)} total reviews.\")\n",
    "print(\"üíæ Saved as 'minimalist_reviews_alpha_arbutin_2.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf776bf-4303-454f-82ec-4b3758274c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\aditya\\anaconda3\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\aditya\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aditya\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aditya\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\aditya\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.8-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp313-cp313-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     ------------------- ---------------- 524.3/981.5 kB 635.4 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 524.3/981.5 kB 635.4 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 786.4/981.5 kB 588.0 kB/s eta 0:00:01\n",
      "     --------------------------------------- 981.5/981.5 kB 602.6 kB/s  0:00:01\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aditya\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: click in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.8-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.17.0)\n",
      "Requirement already satisfied: six in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from langdetect) (1.17.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.8-cp313-cp313-win_amd64.whl (14.2 MB)\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.2 MB 935.5 kB/s eta 0:00:15\n",
      "   -- ------------------------------------- 1.0/14.2 MB 1.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.3/14.2 MB 1.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.6/14.2 MB 1.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.8/14.2 MB 1.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.4/14.2 MB 1.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.6/14.2 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.9/14.2 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.1/14.2 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.4/14.2 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.7/14.2 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.9/14.2 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.9/14.2 MB 1.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.2/14.2 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 4.7/14.2 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.7/14.2 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.0/14.2 MB 1.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.5/14.2 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.8/14.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.0/14.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.3/14.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.6/14.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.1/14.2 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.3/14.2 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.6/14.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 7.9/14.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.1/14.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.4/14.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 8.9/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 9.2/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 9.2/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.4/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 9.7/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.0/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.0/14.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.2/14.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.2/14.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.2/14.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.5/14.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.5/14.2 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 10.7/14.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.7/14.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.0/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.0/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.0/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 12.3/14.2 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.8/14.2 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.8/14.2 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.1/14.2 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 13.4/14.2 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.6/14.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/14.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.2/14.2 MB 1.0 MB/s  0:00:13\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl (39 kB)\n",
      "Downloading murmurhash-1.0.13-cp313-cp313-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp313-cp313-win_amd64.whl (115 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "   ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/630.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 630.6/630.6 kB 950.4 kB/s  0:00:00\n",
      "Downloading thinc-8.3.8-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 534.0 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.8/1.7 MB 586.4 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.7 MB 586.4 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 650.6 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 650.6 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 1.3/1.7 MB 653.4 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 676.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 691.3 kB/s  0:00:02\n",
      "Downloading blis-1.3.0-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 761.1 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.8/6.3 MB 821.3 kB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.0/6.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.6/6.3 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.3 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 2.4/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.9/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.1/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 3.1/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.4/6.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.9/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.9/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 4.2/6.3 MB 1.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 5.0/6.3 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 5.2/6.3 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 996.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 996.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 952.7 kB/s  0:00:06\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.2-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading gensim-4.4.0-cp313-cp313-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/24.4 MB 1.6 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.8/24.4 MB 1.3 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 0.8/24.4 MB 1.3 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 1.0/24.4 MB 978.4 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 1.0/24.4 MB 978.4 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.3/24.4 MB 855.5 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 1.6/24.4 MB 874.6 kB/s eta 0:00:27\n",
      "   -- ------------------------------------- 1.6/24.4 MB 874.6 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 1.8/24.4 MB 833.4 kB/s eta 0:00:28\n",
      "   --- ------------------------------------ 1.8/24.4 MB 833.4 kB/s eta 0:00:28\n",
      "   --- ------------------------------------ 2.1/24.4 MB 846.5 kB/s eta 0:00:27\n",
      "   --- ------------------------------------ 2.4/24.4 MB 848.1 kB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 2.6/24.4 MB 868.5 kB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 2.9/24.4 MB 904.7 kB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 2.9/24.4 MB 904.7 kB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 3.1/24.4 MB 876.4 kB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 3.1/24.4 MB 876.4 kB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 840.6 kB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 840.6 kB/s eta 0:00:25\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 840.6 kB/s eta 0:00:25\n",
      "   ------ --------------------------------- 3.7/24.4 MB 772.5 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 3.7/24.4 MB 772.5 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 3.7/24.4 MB 772.5 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 3.9/24.4 MB 727.4 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 3.9/24.4 MB 727.4 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 3.9/24.4 MB 727.4 kB/s eta 0:00:29\n",
      "   ------ --------------------------------- 4.2/24.4 MB 688.1 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 4.2/24.4 MB 688.1 kB/s eta 0:00:30\n",
      "   ------ --------------------------------- 4.2/24.4 MB 688.1 kB/s eta 0:00:30\n",
      "   ------- -------------------------------- 4.5/24.4 MB 656.6 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 4.5/24.4 MB 656.6 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 4.7/24.4 MB 655.9 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 4.7/24.4 MB 655.9 kB/s eta 0:00:31\n",
      "   ------- -------------------------------- 4.7/24.4 MB 655.9 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 5.0/24.4 MB 637.5 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 5.0/24.4 MB 637.5 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 5.2/24.4 MB 636.1 kB/s eta 0:00:31\n",
      "   -------- ------------------------------- 5.2/24.4 MB 636.1 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 5.5/24.4 MB 632.4 kB/s eta 0:00:30\n",
      "   --------- ------------------------------ 5.5/24.4 MB 632.4 kB/s eta 0:00:30\n",
      "   --------- ------------------------------ 5.8/24.4 MB 622.7 kB/s eta 0:00:30\n",
      "   --------- ------------------------------ 5.8/24.4 MB 622.7 kB/s eta 0:00:30\n",
      "   --------- ------------------------------ 5.8/24.4 MB 622.7 kB/s eta 0:00:30\n",
      "   --------- ------------------------------ 5.8/24.4 MB 622.7 kB/s eta 0:00:30\n",
      "   --------- ------------------------------ 6.0/24.4 MB 607.3 kB/s eta 0:00:31\n",
      "   --------- ------------------------------ 6.0/24.4 MB 607.3 kB/s eta 0:00:31\n",
      "   ---------- ----------------------------- 6.3/24.4 MB 606.7 kB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 6.3/24.4 MB 606.7 kB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 6.6/24.4 MB 600.6 kB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 6.6/24.4 MB 600.6 kB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 6.8/24.4 MB 607.4 kB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 7.1/24.4 MB 612.5 kB/s eta 0:00:29\n",
      "   ------------ --------------------------- 7.3/24.4 MB 622.0 kB/s eta 0:00:28\n",
      "   ------------ --------------------------- 7.3/24.4 MB 622.0 kB/s eta 0:00:28\n",
      "   ------------ --------------------------- 7.6/24.4 MB 623.0 kB/s eta 0:00:27\n",
      "   ------------ --------------------------- 7.6/24.4 MB 623.0 kB/s eta 0:00:27\n",
      "   ------------ --------------------------- 7.9/24.4 MB 620.1 kB/s eta 0:00:27\n",
      "   ------------ --------------------------- 7.9/24.4 MB 620.1 kB/s eta 0:00:27\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   ------------- -------------------------- 8.1/24.4 MB 626.7 kB/s eta 0:00:26\n",
      "   -------------- ------------------------- 8.7/24.4 MB 542.1 kB/s eta 0:00:30\n",
      "   --------------- ------------------------ 9.2/24.4 MB 568.3 kB/s eta 0:00:27\n",
      "   --------------- ------------------------ 9.4/24.4 MB 578.7 kB/s eta 0:00:26\n",
      "   --------------- ------------------------ 9.7/24.4 MB 582.8 kB/s eta 0:00:26\n",
      "   --------------- ------------------------ 9.7/24.4 MB 582.8 kB/s eta 0:00:26\n",
      "   ---------------- ----------------------- 10.0/24.4 MB 586.8 kB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 10.2/24.4 MB 589.8 kB/s eta 0:00:25\n",
      "   ---------------- ----------------------- 10.2/24.4 MB 589.8 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 593.8 kB/s eta 0:00:24\n",
      "   ------------------ --------------------- 11.3/24.4 MB 561.4 kB/s eta 0:00:24\n",
      "   ------------------ --------------------- 11.5/24.4 MB 568.2 kB/s eta 0:00:23\n",
      "   ------------------ --------------------- 11.5/24.4 MB 568.2 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 11.8/24.4 MB 570.4 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 11.8/24.4 MB 570.4 kB/s eta 0:00:23\n",
      "   ------------------- -------------------- 12.1/24.4 MB 568.1 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 12.1/24.4 MB 568.1 kB/s eta 0:00:22\n",
      "   -------------------- ------------------- 12.3/24.4 MB 568.0 kB/s eta 0:00:22\n",
      "   -------------------- ------------------- 12.3/24.4 MB 568.0 kB/s eta 0:00:22\n",
      "   -------------------- ------------------- 12.3/24.4 MB 568.0 kB/s eta 0:00:22\n",
      "   -------------------- ------------------- 12.6/24.4 MB 564.6 kB/s eta 0:00:21\n",
      "   -------------------- ------------------- 12.6/24.4 MB 564.6 kB/s eta 0:00:21\n",
      "   --------------------- ------------------ 12.8/24.4 MB 564.4 kB/s eta 0:00:21\n",
      "   --------------------- ------------------ 12.8/24.4 MB 564.4 kB/s eta 0:00:21\n",
      "   --------------------- ------------------ 13.1/24.4 MB 566.4 kB/s eta 0:00:20\n",
      "   --------------------- ------------------ 13.1/24.4 MB 566.4 kB/s eta 0:00:20\n",
      "   --------------------- ------------------ 13.4/24.4 MB 568.4 kB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 13.6/24.4 MB 569.8 kB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 13.6/24.4 MB 569.8 kB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 13.6/24.4 MB 569.8 kB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 13.9/24.4 MB 568.7 kB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 14.2/24.4 MB 571.2 kB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 14.2/24.4 MB 571.2 kB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 14.4/24.4 MB 571.8 kB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 14.4/24.4 MB 571.8 kB/s eta 0:00:18\n",
      "   ------------------------ --------------- 14.7/24.4 MB 577.3 kB/s eta 0:00:17\n",
      "   ------------------------ --------------- 14.9/24.4 MB 578.7 kB/s eta 0:00:17\n",
      "   ------------------------ --------------- 15.2/24.4 MB 584.2 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 15.2/24.4 MB 584.2 kB/s eta 0:00:16\n",
      "   ------------------------- -------------- 15.5/24.4 MB 586.9 kB/s eta 0:00:16\n",
      "   ------------------------- -------------- 15.5/24.4 MB 586.9 kB/s eta 0:00:16\n",
      "   ------------------------- -------------- 15.7/24.4 MB 588.0 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   -------------------------- ------------- 16.0/24.4 MB 589.6 kB/s eta 0:00:15\n",
      "   --------------------------- ------------ 16.8/24.4 MB 581.3 kB/s eta 0:00:14\n",
      "   --------------------------- ------------ 17.0/24.4 MB 587.1 kB/s eta 0:00:13\n",
      "   --------------------------- ------------ 17.0/24.4 MB 587.1 kB/s eta 0:00:13\n",
      "   --------------------------- ------------ 17.0/24.4 MB 587.1 kB/s eta 0:00:13\n",
      "   --------------------------- ------------ 17.0/24.4 MB 587.1 kB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 17.3/24.4 MB 581.0 kB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 17.3/24.4 MB 581.0 kB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 17.6/24.4 MB 581.5 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 17.6/24.4 MB 581.5 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 17.6/24.4 MB 581.5 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 17.6/24.4 MB 581.5 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 17.6/24.4 MB 581.5 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 17.6/24.4 MB 581.5 kB/s eta 0:00:12\n",
      "   ------------------------------ --------- 18.4/24.4 MB 563.8 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.4/24.4 MB 563.8 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.4/24.4 MB 563.8 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.6/24.4 MB 560.4 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.6/24.4 MB 560.4 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.6/24.4 MB 560.4 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.6/24.4 MB 560.4 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.9/24.4 MB 543.7 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.9/24.4 MB 543.7 kB/s eta 0:00:11\n",
      "   ------------------------------ --------- 18.9/24.4 MB 543.7 kB/s eta 0:00:11\n",
      "   ------------------------------- -------- 19.1/24.4 MB 532.0 kB/s eta 0:00:10\n",
      "   ------------------------------- -------- 19.1/24.4 MB 532.0 kB/s eta 0:00:10\n",
      "   ------------------------------- -------- 19.1/24.4 MB 532.0 kB/s eta 0:00:10\n",
      "   ------------------------------- -------- 19.1/24.4 MB 532.0 kB/s eta 0:00:10\n",
      "   ------------------------------- -------- 19.4/24.4 MB 528.9 kB/s eta 0:00:10\n",
      "   ------------------------------- -------- 19.4/24.4 MB 528.9 kB/s eta 0:00:10\n",
      "   -------------------------------- ------- 19.7/24.4 MB 533.0 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 19.7/24.4 MB 533.0 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 19.9/24.4 MB 535.3 kB/s eta 0:00:09\n",
      "   -------------------------------- ------- 19.9/24.4 MB 535.3 kB/s eta 0:00:09\n",
      "   --------------------------------- ------ 20.2/24.4 MB 538.0 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 20.2/24.4 MB 538.0 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 20.2/24.4 MB 538.0 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 20.4/24.4 MB 541.4 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 20.4/24.4 MB 541.4 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 20.7/24.4 MB 542.7 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 21.0/24.4 MB 545.5 kB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 21.2/24.4 MB 550.8 kB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 21.5/24.4 MB 559.1 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 22.0/24.4 MB 569.1 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 22.0/24.4 MB 569.1 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 22.0/24.4 MB 569.1 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 22.3/24.4 MB 568.9 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 22.5/24.4 MB 572.0 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 23.1/24.4 MB 554.5 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 23.3/24.4 MB 554.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.3/24.4 MB 554.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.3/24.4 MB 554.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.6/24.4 MB 545.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.6/24.4 MB 545.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 23.6/24.4 MB 545.1 kB/s eta 0:00:02\n",
      "   ---------------------------------------  23.9/24.4 MB 542.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.4 MB 542.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.4 MB 542.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.4 MB 542.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 587.0 kB/s  0:00:43\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/608.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/608.4 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/608.4 kB ? eta -:--:--\n",
      "   -------------------------------- ----- 524.3/608.4 kB 480.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 608.4/608.4 kB 463.0 kB/s  0:00:01\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml): started\n",
      "  Building wheel for langdetect (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993363 sha256=a4987e69dda6f3cd353d046e863b6a9c70d1eff484e77113ede2287b70e05802\n",
      "  Stored in directory: c:\\users\\aditya\\appdata\\local\\pip\\cache\\wheels\\eb\\87\\25\\2dddf1c94e1786054e25022ec5530bfed52bad86d882999c48\n",
      "Successfully built langdetect\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, langdetect, emoji, cloudpathlib, catalogue, blis, typer-slim, srsly, preshed, gensim, deep-translator, confection, weasel, thinc, spacy\n",
      "\n",
      "   -- -------------------------------------  1/20 [wasabi]\n",
      "   -- -------------------------------------  1/20 [wasabi]\n",
      "   ---- -----------------------------------  2/20 [spacy-loggers]\n",
      "   ------ ---------------------------------  3/20 [spacy-legacy]\n",
      "   ------ ---------------------------------  3/20 [spacy-legacy]\n",
      "   ------ ---------------------------------  3/20 [spacy-legacy]\n",
      "   -------- -------------------------------  4/20 [smart-open]\n",
      "   -------- -------------------------------  4/20 [smart-open]\n",
      "   -------- -------------------------------  4/20 [smart-open]\n",
      "   ---------- -----------------------------  5/20 [murmurhash]\n",
      "   ------------ ---------------------------  6/20 [langdetect]\n",
      "   ------------ ---------------------------  6/20 [langdetect]\n",
      "   ------------ ---------------------------  6/20 [langdetect]\n",
      "   -------------- -------------------------  7/20 [emoji]\n",
      "   -------------- -------------------------  7/20 [emoji]\n",
      "   ---------------- -----------------------  8/20 [cloudpathlib]\n",
      "   ---------------- -----------------------  8/20 [cloudpathlib]\n",
      "   ---------------- -----------------------  8/20 [cloudpathlib]\n",
      "   -------------------- ------------------- 10/20 [blis]\n",
      "   -------------------- ------------------- 10/20 [blis]\n",
      "   -------------------- ------------------- 10/20 [blis]\n",
      "   ---------------------- ----------------- 11/20 [typer-slim]\n",
      "   ---------------------- ----------------- 11/20 [typer-slim]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   ------------------------ --------------- 12/20 [srsly]\n",
      "   -------------------------- ------------- 13/20 [preshed]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ---------------------------- ----------- 14/20 [gensim]\n",
      "   ------------------------------ --------- 15/20 [deep-translator]\n",
      "   -------------------------------- ------- 16/20 [confection]\n",
      "   -------------------------------- ------- 16/20 [confection]\n",
      "   ---------------------------------- ----- 17/20 [weasel]\n",
      "   ---------------------------------- ----- 17/20 [weasel]\n",
      "   ---------------------------------- ----- 17/20 [weasel]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   ------------------------------------ --- 18/20 [thinc]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   -------------------------------------- - 19/20 [spacy]\n",
      "   ---------------------------------------- 20/20 [spacy]\n",
      "\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.11 deep-translator-1.11.4 emoji-2.15.0 gensim-4.4.0 langdetect-1.0.9 murmurhash-1.0.13 preshed-3.0.10 smart-open-7.5.0 spacy-3.8.8 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.8 typer-slim-0.20.0 wasabi-1.1.3 weasel-0.4.2\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.9 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 2.6/12.8 MB 1.5 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 4.5/12.8 MB 1.8 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 5.0/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 1.9 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.0 MB/s eta 0:00:04\n",
      "     -------------------- ------------------- 6.6/12.8 MB 2.0 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 2.1 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.9/12.8 MB 2.0 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.9 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 8.7/12.8 MB 2.0 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 2.0 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.7/12.8 MB 2.0 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.0 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.0 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 2.0 MB/s  0:00:06\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# üì¶ INSTALLS (run once per environment)\n",
    "# ================================================\n",
    "import sys\n",
    "pip = sys.executable\n",
    "\n",
    "# Safer installs inside Anaconda/Jupyter\n",
    "!{pip} -m pip install --upgrade pip\n",
    "!{pip} -m pip install pandas numpy scikit-learn nltk spacy gensim langdetect deep-translator emoji matplotlib\n",
    "!{pip} -m spacy download en_core_web_sm\n",
    "\n",
    "# Optional Hindi tokenizer (for better pre-translation cleanup; rule-based)\n",
    "# (No Transformer models are used.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5fe5c-029e-425b-aae8-1b0b03d55203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560aeff-369a-4193-8c64-a5c9c5abaa74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13c652-74c7-46b4-bb38-9ccf89eeb88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54355afd-6ee9-4ce1-bc4e-ba76b65a5d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b05dd-c4a8-460a-98f2-2f436f2dd851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800c5b4a-80ea-4196-9eeb-fa7dd9bacd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Core libs (non-Transformer)\n",
    "!{sys.executable} -m pip install --quiet langdetect deep-translator spacy gensim scikit-learn matplotlib\n",
    "\n",
    "# NLTK is optional; we handle offline gracefully if corpora can't download\n",
    "!{sys.executable} -m pip install --quiet nltk\n",
    "\n",
    "# Try to fetch a small spaCy model (non-Transformer). If your network blocks this, we'll fall back.\n",
    "try:\n",
    "    import spacy\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "except Exception:\n",
    "    try:\n",
    "        !{sys.executable} -m spacy download en_core_web_sm\n",
    "    except Exception as e:\n",
    "        print(\"spaCy model download failed; will use rule-based fallbacks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4df347f-fcc7-4802-b097-3e8775f603ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# Core libs (non-Transformer)\n",
    "!{sys.executable} -m pip install --quiet langdetect deep-translator spacy gensim scikit-learn matplotlib\n",
    "\n",
    "# NLTK is optional; we handle offline gracefully if corpora can't download\n",
    "!{sys.executable} -m pip install --quiet nltk\n",
    "\n",
    "# Try to fetch a small spaCy model (non-Transformer). If your network blocks this, we'll fall back.\n",
    "try:\n",
    "    import spacy\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "except Exception:\n",
    "    try:\n",
    "        !{sys.executable} -m spacy download en_core_web_sm\n",
    "    except Exception as e:\n",
    "        print(\"spaCy model download failed; will use rule-based fallbacks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aae4faf-0c63-4982-a1ee-263c34fbf095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['S.No', 'Name', 'Date', 'Rating', 'Title', 'Review']\n",
      "Missing expected: set()\n",
      "Rows: 250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No           Name                    Date  Rating  \\\n",
       "0     1  Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2   Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3    Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "\n",
       "                     Title                   Review  \n",
       "0  Sach a good serums. . .  Sach a good serums. . .  \n",
       "1         It's really good         It's really good  \n",
       "2           Great products           Great products  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1 ‚Äî load data\n",
    "import os, pandas as pd\n",
    "\n",
    "INPUT_CSV = \"minimalist_reviews_alpha_arbutin_2.csv\"  # change if needed\n",
    "assert os.path.exists(INPUT_CSV), f\"CSV not found at {INPUT_CSV}\"\n",
    "\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "expected_cols = {\"Review\",\"Rating\",\"Name\",\"Date\",\"Title\"}\n",
    "missing = expected_cols - set(df.columns)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"Missing expected:\", missing)\n",
    "\n",
    "# keep the columns you need\n",
    "df = df.rename(columns={c:c.strip() for c in df.columns})\n",
    "df = df[[c for c in [\"S.No\",\"Name\",\"Date\",\"Rating\",\"Title\",\"Review\"] if c in df.columns]]\n",
    "df = df.dropna(subset=[\"Review\"]).reset_index(drop=True)\n",
    "print(\"Rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "760b748b-7088-48fa-94e1-781175a70597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang  \n",
       "0   en  \n",
       "1   en  \n",
       "2   en  \n",
       "3   en  \n",
       "4   en  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 42\n",
    "\n",
    "df = pd.read_csv(\"minimalist_reviews_alpha_arbutin_2.csv\")\n",
    "\n",
    "# Ensure column name is correct\n",
    "assert \"Review\" in df.columns, \"CSV must contain a column named 'Review'\"\n",
    "\n",
    "def detect_lang_safe(t):\n",
    "    try:\n",
    "        return detect(str(t)) if str(t).strip() else \"unknown\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"lang\"] = df[\"Review\"].astype(str).map(detect_lang_safe)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39b1467b-db2f-4165-9df0-a619b1b9a96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \n",
       "0   en                            Sach a good serums. . .  \n",
       "1   en                                   It's really good  \n",
       "2   en                                     Great products  \n",
       "3   en  I can see the difference in my skin. My skin u...  \n",
       "4   en  I can only say that the product is good but no...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_to_en(text, lang):\n",
    "    if lang == \"en\" or lang == \"unknown\":\n",
    "        return text\n",
    "    try:\n",
    "        return GoogleTranslator(source=lang, target=\"en\").translate(text)\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "df[\"text_en\"] = df.apply(lambda r: translate_to_en(r[\"Review\"], r[\"lang\"]), axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a45668af-b9ae-4fe1-93d7-c50077dc926c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \n",
       "0                            sach a good serums. . .  \n",
       "1                                   it s really good  \n",
       "2                                     great products  \n",
       "3  i can see the difference in my skin. my skin u...  \n",
       "4  i can only say that the product is good but no...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"http\\S+|www.\\S+\", \" \", s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s.,!?]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"clean\"] = df[\"text_en\"].map(clean_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8143f57-cecd-4dd2-b50e-8a76a761671a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \n",
       "0                            [sach, a, good, serums]  \n",
       "1                              [it, s, really, good]  \n",
       "2                                  [great, products]  \n",
       "3  [i, can, see, the, difference, in, my, skin, m...  \n",
       "4  [i, can, only, say, that, the, product, is, go...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(s):\n",
    "    return re.findall(r\"[a-z]+\", s)\n",
    "\n",
    "df[\"tokens\"] = df[\"clean\"].map(tokenize)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "081917aa-c0cf-4cf1-93c2-52d451c54130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \n",
       "0                               [sach, good, serums]  \n",
       "1                                  [s, really, good]  \n",
       "2                                  [great, products]  \n",
       "3  [see, difference, skin, skin, used, dull, has,...  \n",
       "4   [say, product, good, good, enough, individually]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(\"\"\"\n",
    "a an the and or but if while is are was were be been being am to for from in on at by of with as into through during\n",
    "about over under again further then once here there when where why how all any both each few more most other some such\n",
    "no nor not only own same so than too very can will just should now \n",
    "i me my we you he she it they this that these those them her his him\n",
    "\"\"\".split())\n",
    "\n",
    "df[\"tokens_nostop\"] = df[\"tokens\"].map(lambda toks: [t for t in toks if t not in STOPWORDS])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef2f7448-71e3-4dc3-b9a3-731765982e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "      <td>[sach, good, serum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "      <td>[s, realli, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "      <td>[see, differ, skin, skin, use, dull, ha, chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "      <td>[say, product, good, good, enough, individu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \\\n",
       "0                               [sach, good, serums]   \n",
       "1                                  [s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [see, difference, skin, skin, used, dull, has,...   \n",
       "4   [say, product, good, good, enough, individually]   \n",
       "\n",
       "                                             stemmed  \n",
       "0                                [sach, good, serum]  \n",
       "1                                  [s, realli, good]  \n",
       "2                                   [great, product]  \n",
       "3  [see, differ, skin, skin, use, dull, ha, chang...  \n",
       "4       [say, product, good, good, enough, individu]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "df[\"stemmed\"] = df[\"tokens_nostop\"].map(lambda toks: [ps.stem(t) for t in toks])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf96f64-8956-4df3-bc29-a8e9d88ab13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved: processed_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"processed_reviews.csv\", index=False)\n",
    "print(\"‚úÖ Saved: processed_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "850088d2-5dec-46de-b6c3-99057bab3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S.No            Name                    Date  Rating  \\\n",
      "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
      "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
      "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
      "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
      "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
      "\n",
      "                     Title                                             Review  \\\n",
      "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
      "1         It's really good                                   It's really good   \n",
      "2           Great products                                     Great products   \n",
      "3          Its really good  I can see the difference in my skin. My skin u...   \n",
      "4               My opinion  I can only say that the product is good but no...   \n",
      "\n",
      "  lang                                            text_en  \\\n",
      "0   en                            Sach a good serums. . .   \n",
      "1   en                                   It's really good   \n",
      "2   en                                     Great products   \n",
      "3   en  I can see the difference in my skin. My skin u...   \n",
      "4   en  I can only say that the product is good but no...   \n",
      "\n",
      "                                               clean  \\\n",
      "0                            sach a good serums. . .   \n",
      "1                                   it s really good   \n",
      "2                                     great products   \n",
      "3  i can see the difference in my skin. my skin u...   \n",
      "4  i can only say that the product is good but no...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0                    ['sach', 'a', 'good', 'serums']   \n",
      "1                      ['it', 's', 'really', 'good']   \n",
      "2                              ['great', 'products']   \n",
      "3  ['i', 'can', 'see', 'the', 'difference', 'in',...   \n",
      "4  ['i', 'can', 'only', 'say', 'that', 'the', 'pr...   \n",
      "\n",
      "                                       tokens_nostop  \\\n",
      "0                         ['sach', 'good', 'serums']   \n",
      "1                            ['s', 'really', 'good']   \n",
      "2                              ['great', 'products']   \n",
      "3  ['see', 'difference', 'skin', 'skin', 'used', ...   \n",
      "4  ['say', 'product', 'good', 'good', 'enough', '...   \n",
      "\n",
      "                                             stemmed  \n",
      "0                          ['sach', 'good', 'serum']  \n",
      "1                            ['s', 'realli', 'good']  \n",
      "2                               ['great', 'product']  \n",
      "3  ['see', 'differ', 'skin', 'skin', 'use', 'dull...  \n",
      "4  ['say', 'product', 'good', 'good', 'enough', '...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed_reviews.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c262acd9-37dc-4016-9670-215baf142014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[(sach, VERB), (a, DET), (good, ADJ), (serums,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it s really good</td>\n",
       "      <td>[(it, PRON), (s, VERB), (really, ADV), (good, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great products</td>\n",
       "      <td>[(great, ADJ), (products, NOUN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[(i, PRON), (can, AUX), (see, VERB), (the, DET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[(i, PRON), (can, AUX), (only, ADV), (say, VER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                                 pos  \n",
       "0  [(sach, VERB), (a, DET), (good, ADJ), (serums,...  \n",
       "1  [(it, PRON), (s, VERB), (really, ADV), (good, ...  \n",
       "2                   [(great, ADJ), (products, NOUN)]  \n",
       "3  [(i, PRON), (can, AUX), (see, VERB), (the, DET...  \n",
       "4  [(i, PRON), (can, AUX), (only, ADV), (say, VER...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Try spaCy\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")  # non-Transformer\n",
    "        SPACY_OK = True\n",
    "    except:\n",
    "        nlp = spacy.blank(\"en\")             # tokenizer only\n",
    "        SPACY_OK = False\n",
    "except:\n",
    "    nlp = None\n",
    "    SPACY_OK = False\n",
    "\n",
    "def pos_tag_safe(text):\n",
    "    if SPACY_OK:\n",
    "        doc = nlp(str(text))\n",
    "        return [(t.text, t.pos_) for t in doc]\n",
    "    else:\n",
    "        words = re.findall(r\"[a-zA-Z]+\", str(text))\n",
    "        return [(w, \"NOUN\" if w[0].isupper() else \"X\") for w in words]  # rule-based fallback\n",
    "\n",
    "df[\"pos\"] = df[\"clean\"].map(pos_tag_safe)\n",
    "df[[\"clean\",\"pos\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc20fd94-ecc6-4e15-ac2a-a603c32ff215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it s really good</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great products</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[(3, CARDINAL)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean         entities\n",
       "0                            sach a good serums. . .               []\n",
       "1                                   it s really good               []\n",
       "2                                     great products               []\n",
       "3  i can see the difference in my skin. my skin u...  [(3, CARDINAL)]\n",
       "4  i can only say that the product is good but no...               []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def ner_safe(text):\n",
    "    if SPACY_OK:\n",
    "        doc = nlp(str(text))\n",
    "        return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    else:\n",
    "        pattern = r\"\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\b\"\n",
    "        return [(m.group(1), \"ENTITY\") for m in re.finditer(pattern,str(text))]\n",
    "\n",
    "df[\"entities\"] = df[\"clean\"].map(ner_safe)\n",
    "df[[\"clean\",\"entities\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04f75eca-36dd-404c-bce3-c03fb016a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing empty: 249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                              sach a good serums. . .\n",
       "1                                     it s really good\n",
       "2                                       great products\n",
       "3    i can see the difference in my skin. my skin u...\n",
       "4    i can only say that the product is good but no...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIX ‚Äî Replace NaN with a safe empty string\n",
    "df[\"clean\"] = df[\"clean\"].fillna(\"\")\n",
    "\n",
    "# Also drop rows where clean text is empty (optional but recommended)\n",
    "df = df[df[\"clean\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "print(\"Rows after removing empty:\", len(df))\n",
    "df[\"clean\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6daeda-e824-4e4b-8562-d4b3debc9786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874089e9-1f91-49f0-b19f-2230cac0b886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ce9a58c-274d-4416-9d07-6f70b0da4cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Shape: (249, 332)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer(min_df=2, max_df=0.9)\n",
    "X_bow = bow.fit_transform(df[\"clean\"])\n",
    "\n",
    "print(\"BOW Shape:\", X_bow.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50d5b026-f972-436f-b85d-af18b3291b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Shape: (249, 672)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.9, ngram_range=(1,2))\n",
    "X_tfidf = tfidf.fit_transform(df[\"clean\"])\n",
    "\n",
    "print(\"TF-IDF Shape:\", X_tfidf.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "004e01bf-b313-490f-8b3a-f4ac27816a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5c3ecd2-2a20-4615-ae4a-30b5bdcb41ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \n",
       "0  Sach a good serums. . .                            Sach a good serums. . .  \n",
       "1         It's really good                                   It's really good  \n",
       "2           Great products                                     Great products  \n",
       "3          Its really good  I can see the difference in my skin. My skin u...  \n",
       "4               My opinion  I can only say that the product is good but no...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"minimalist_reviews_alpha_arbutin_2.csv\")\n",
    "\n",
    "assert \"Review\" in df.columns, \"CSV must contain a 'Review' column\"\n",
    "df = df.dropna(subset=[\"Review\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Loaded rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b74bb74c-554b-490e-8084-59dd7345a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang  \n",
       "0   en  \n",
       "1   en  \n",
       "2   en  \n",
       "3   en  \n",
       "4   en  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 42\n",
    "\n",
    "def detect_lang_safe(text):\n",
    "    try:\n",
    "        return detect(str(text)) if str(text).strip() else \"unknown\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"lang\"] = df[\"Review\"].map(detect_lang_safe)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a13815d1-cc26-4d9f-81cb-50aed800d60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \n",
       "0   en                            Sach a good serums. . .  \n",
       "1   en                                   It's really good  \n",
       "2   en                                     Great products  \n",
       "3   en  I can see the difference in my skin. My skin u...  \n",
       "4   en  I can only say that the product is good but no...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_to_en(text, lang):\n",
    "    if lang in (\"en\",\"unknown\"):\n",
    "        return text\n",
    "    try:\n",
    "        return GoogleTranslator(source=lang, target=\"en\").translate(text)\n",
    "    except:\n",
    "        return text   # keep original if blocked\n",
    "\n",
    "df[\"text_en\"] = df.apply(lambda r: translate_to_en(r[\"Review\"], r[\"lang\"]), axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "034e1f54-c296-4851-a5e1-04f32cbe69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning: 249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \n",
       "0                            sach a good serums. . .  \n",
       "1                                   it s really good  \n",
       "2                                     great products  \n",
       "3  i can see the difference in my skin. my skin u...  \n",
       "4  i can only say that the product is good but no...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\",\" \", s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s.,!?]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\",\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"clean\"] = df[\"text_en\"].map(clean_text)\n",
    "\n",
    "# FIX: Remove NaN and empty rows\n",
    "df[\"clean\"] = df[\"clean\"].fillna(\"\")\n",
    "df = df[df[\"clean\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "print(\"Rows after cleaning:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1add75d7-713f-4a0c-b3c4-7b1e462b1b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \n",
       "0                            [sach, a, good, serums]  \n",
       "1                              [it, s, really, good]  \n",
       "2                                  [great, products]  \n",
       "3  [i, can, see, the, difference, in, my, skin, m...  \n",
       "4  [i, can, only, say, that, the, product, is, go...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_regex(s):\n",
    "    return re.findall(r\"[a-z]+\", str(s))\n",
    "\n",
    "df[\"tokens\"] = df[\"clean\"].map(tokenize_regex)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5366badd-81fc-427b-a31c-d4f54fc39c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \n",
       "0                               [sach, good, serums]  \n",
       "1                                  [s, really, good]  \n",
       "2                                  [great, products]  \n",
       "3  [see, difference, skin, skin, used, dull, has,...  \n",
       "4   [say, product, good, good, enough, individually]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(\"\"\"\n",
    "a an the and or but if while is are was were be been being am to for from in on at by of with as into through during\n",
    "about over under again further then once here there when where why how all any both each few more most other some such\n",
    "no nor not only own same so than too very can will just should now \n",
    "i me my we you he she it they this that these those them her his him\n",
    "\"\"\".split())\n",
    "\n",
    "df[\"tokens_nostop\"] = df[\"tokens\"].map(lambda toks: [t for t in toks if t not in STOPWORDS])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7dfe2d9-28e9-4062-bd42-96e9130363c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "      <td>[sach, good, serum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "      <td>[s, realli, good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "      <td>[see, differ, skin, skin, use, dull, ha, chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "      <td>[say, product, good, good, enough, individu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \\\n",
       "0                               [sach, good, serums]   \n",
       "1                                  [s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [see, difference, skin, skin, used, dull, has,...   \n",
       "4   [say, product, good, good, enough, individually]   \n",
       "\n",
       "                                             stemmed  \n",
       "0                                [sach, good, serum]  \n",
       "1                                  [s, realli, good]  \n",
       "2                                   [great, product]  \n",
       "3  [see, differ, skin, skin, use, dull, ha, chang...  \n",
       "4       [say, product, good, good, enough, individu]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "df[\"stemmed\"] = df[\"tokens_nostop\"].map(lambda toks: [ps.stem(t) for t in toks])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15f01bb7-d9d5-4b06-ae6d-8b0be5fcf496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "      <td>[sach, good, serum]</td>\n",
       "      <td>[(sach, VERB), (a, DET), (good, ADJ), (serums,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "      <td>[s, realli, good]</td>\n",
       "      <td>[(it, PRON), (s, VERB), (really, ADV), (good, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, product]</td>\n",
       "      <td>[(great, ADJ), (products, NOUN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "      <td>[see, differ, skin, skin, use, dull, ha, chang...</td>\n",
       "      <td>[(i, PRON), (can, AUX), (see, VERB), (the, DET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "      <td>[say, product, good, good, enough, individu]</td>\n",
       "      <td>[(i, PRON), (can, AUX), (only, ADV), (say, VER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \\\n",
       "0                               [sach, good, serums]   \n",
       "1                                  [s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [see, difference, skin, skin, used, dull, has,...   \n",
       "4   [say, product, good, good, enough, individually]   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0                                [sach, good, serum]   \n",
       "1                                  [s, realli, good]   \n",
       "2                                   [great, product]   \n",
       "3  [see, differ, skin, skin, use, dull, ha, chang...   \n",
       "4       [say, product, good, good, enough, individu]   \n",
       "\n",
       "                                                 pos  \n",
       "0  [(sach, VERB), (a, DET), (good, ADJ), (serums,...  \n",
       "1  [(it, PRON), (s, VERB), (really, ADV), (good, ...  \n",
       "2                   [(great, ADJ), (products, NOUN)]  \n",
       "3  [(i, PRON), (can, AUX), (see, VERB), (the, DET...  \n",
       "4  [(i, PRON), (can, AUX), (only, ADV), (say, VER...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        SPACY_OK = True\n",
    "    except:\n",
    "        nlp = spacy.blank(\"en\")  # tokenizer only\n",
    "        SPACY_OK = False\n",
    "except:\n",
    "    nlp = None\n",
    "    SPACY_OK = False\n",
    "\n",
    "def pos_safe(text):\n",
    "    if SPACY_OK:\n",
    "        return [(t.text, t.pos_) for t in nlp(text)]\n",
    "    else:\n",
    "        # fallback rule-based\n",
    "        words = re.findall(r\"[A-Za-z]+\", text)\n",
    "        return [(w, \"NOUN\" if w[0].isupper() else \"X\") for w in words]\n",
    "\n",
    "df[\"pos\"] = df[\"clean\"].map(pos_safe)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fee9ffb5-b8ec-43a4-9353-50dfccc25441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>pos</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "      <td>[sach, good, serum]</td>\n",
       "      <td>[(sach, VERB), (a, DET), (good, ADJ), (serums,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "      <td>[s, realli, good]</td>\n",
       "      <td>[(it, PRON), (s, VERB), (really, ADV), (good, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, product]</td>\n",
       "      <td>[(great, ADJ), (products, NOUN)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "      <td>[see, differ, skin, skin, use, dull, ha, chang...</td>\n",
       "      <td>[(i, PRON), (can, AUX), (see, VERB), (the, DET...</td>\n",
       "      <td>[(3, CARDINAL)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "      <td>[say, product, good, good, enough, individu]</td>\n",
       "      <td>[(i, PRON), (can, AUX), (only, ADV), (say, VER...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \\\n",
       "0                               [sach, good, serums]   \n",
       "1                                  [s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [see, difference, skin, skin, used, dull, has,...   \n",
       "4   [say, product, good, good, enough, individually]   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0                                [sach, good, serum]   \n",
       "1                                  [s, realli, good]   \n",
       "2                                   [great, product]   \n",
       "3  [see, differ, skin, skin, use, dull, ha, chang...   \n",
       "4       [say, product, good, good, enough, individu]   \n",
       "\n",
       "                                                 pos         entities  \n",
       "0  [(sach, VERB), (a, DET), (good, ADJ), (serums,...               []  \n",
       "1  [(it, PRON), (s, VERB), (really, ADV), (good, ...               []  \n",
       "2                   [(great, ADJ), (products, NOUN)]               []  \n",
       "3  [(i, PRON), (can, AUX), (see, VERB), (the, DET...  [(3, CARDINAL)]  \n",
       "4  [(i, PRON), (can, AUX), (only, ADV), (say, VER...               []  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ner_safe(text):\n",
    "    if SPACY_OK:\n",
    "        return [(e.text, e.label_) for e in nlp(text).ents]\n",
    "    else:\n",
    "        pattern = r\"\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\b\"\n",
    "        return [(m.group(1),\"ENTITY\") for m in re.finditer(pattern,text)]\n",
    "\n",
    "df[\"entities\"] = df[\"clean\"].map(ner_safe)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a11dae3-fcd0-4483-9bac-24a13201271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW shape: (249, 332)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer(min_df=2, max_df=0.9)\n",
    "X_bow = bow.fit_transform(df[\"clean\"])\n",
    "\n",
    "print(\"BOW shape:\", X_bow.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18b41333-39a3-40d8-be7a-5ca2531fe478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (249, 672)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.9, ngram_range=(1,2))\n",
    "X_tfidf = tfidf.fit_transform(df[\"clean\"])\n",
    "\n",
    "print(\"TF-IDF shape:\", X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d021628-1197-4ebf-8426-a3215dac5286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar words to 'skin':\n",
      "[('serum', 0.9994896650314331), ('use', 0.9993718266487122), ('result', 0.9992791414260864), ('acn', 0.9992438554763794), ('after', 0.9992356300354004), ('product', 0.9991717338562012), ('see', 0.99917072057724), ('bottl', 0.9991689920425415), ('packag', 0.9991459846496582), ('work', 0.9991435408592224)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = df[\"stemmed\"].tolist()\n",
    "\n",
    "w2v = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=2, epochs=20)\n",
    "\n",
    "print(\"similar words to 'skin':\")\n",
    "try:\n",
    "    print(w2v.wv.most_similar(\"skin\"))\n",
    "except:\n",
    "    print(\"not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95da84f9-cd74-4b1e-b7bd-efbaff44b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 1: ['good', 'product', 'good product', 'it', 'the', 'and', 'my', 'this', 'for', 'skin']\n",
      "TOPIC 2: ['good', 'good product', 'very good', 'product', 'good one', 'it good', 'very', 'good for', 'feel', 'good results']\n",
      "TOPIC 3: ['product', 'good product', 'the', 'this product', 'the product', 'this', 'nice product', 'nice', 'love', 'product is']\n",
      "TOPIC 4: ['the', 'very', 'the product', 'very good', 'effective', 'product is', 'really', 'is', 'love', 'it really']\n",
      "TOPIC 5: ['skin', 'and', 'very', 'my skin', 'my', 'good for', 'good product', 'very good', 'glowing', 'skin and']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "lsa = TruncatedSVD(n_components=5, random_state=42)\n",
    "lsa_matrix = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "terms = tfidf.get_feature_names_out()\n",
    "\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    idx = comp.argsort()[::-1][:10]\n",
    "    print(f\"TOPIC {i+1}:\", [terms[j] for j in idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15e361c2-f6bb-4d3a-a39a-f8cba7ae2294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_nostop</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>pos</th>\n",
       "      <th>entities</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Anamika M. üáÆüá≥</td>\n",
       "      <td>Published date02/10/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>en</td>\n",
       "      <td>Sach a good serums. . .</td>\n",
       "      <td>sach a good serums. . .</td>\n",
       "      <td>[sach, a, good, serums]</td>\n",
       "      <td>[sach, good, serums]</td>\n",
       "      <td>[sach, good, serum]</td>\n",
       "      <td>[(sach, VERB), (a, DET), (good, ADJ), (serums,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahima K. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>en</td>\n",
       "      <td>It's really good</td>\n",
       "      <td>it s really good</td>\n",
       "      <td>[it, s, really, good]</td>\n",
       "      <td>[s, really, good]</td>\n",
       "      <td>[s, realli, good]</td>\n",
       "      <td>[(it, PRON), (s, VERB), (really, ADV), (good, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy R. üáÆüá≥</td>\n",
       "      <td>Published date30/09/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Great products</td>\n",
       "      <td>Great products</td>\n",
       "      <td>en</td>\n",
       "      <td>Great products</td>\n",
       "      <td>great products</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, products]</td>\n",
       "      <td>[great, product]</td>\n",
       "      <td>[(great, ADJ), (products, NOUN)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Meghna M. üáÆüá≥</td>\n",
       "      <td>Published date13/07/25</td>\n",
       "      <td>5</td>\n",
       "      <td>Its really good</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can see the difference in my skin. My skin u...</td>\n",
       "      <td>i can see the difference in my skin. my skin u...</td>\n",
       "      <td>[i, can, see, the, difference, in, my, skin, m...</td>\n",
       "      <td>[see, difference, skin, skin, used, dull, has,...</td>\n",
       "      <td>[see, differ, skin, skin, use, dull, ha, chang...</td>\n",
       "      <td>[(i, PRON), (can, AUX), (see, VERB), (the, DET...</td>\n",
       "      <td>[(3, CARDINAL)]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vaishali k. üáÆüá≥</td>\n",
       "      <td>Published date26/08/25</td>\n",
       "      <td>3</td>\n",
       "      <td>My opinion</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>en</td>\n",
       "      <td>I can only say that the product is good but no...</td>\n",
       "      <td>i can only say that the product is good but no...</td>\n",
       "      <td>[i, can, only, say, that, the, product, is, go...</td>\n",
       "      <td>[say, product, good, good, enough, individually]</td>\n",
       "      <td>[say, product, good, good, enough, individu]</td>\n",
       "      <td>[(i, PRON), (can, AUX), (only, ADV), (say, VER...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No            Name                    Date  Rating  \\\n",
       "0     1   Anamika M. üáÆüá≥  Published date02/10/25       5   \n",
       "1     2    Mahima K. üáÆüá≥  Published date30/09/25       5   \n",
       "2     3     Nancy R. üáÆüá≥  Published date30/09/25       5   \n",
       "3     4    Meghna M. üáÆüá≥  Published date13/07/25       5   \n",
       "4     5  Vaishali k. üáÆüá≥  Published date26/08/25       3   \n",
       "\n",
       "                     Title                                             Review  \\\n",
       "0  Sach a good serums. . .                            Sach a good serums. . .   \n",
       "1         It's really good                                   It's really good   \n",
       "2           Great products                                     Great products   \n",
       "3          Its really good  I can see the difference in my skin. My skin u...   \n",
       "4               My opinion  I can only say that the product is good but no...   \n",
       "\n",
       "  lang                                            text_en  \\\n",
       "0   en                            Sach a good serums. . .   \n",
       "1   en                                   It's really good   \n",
       "2   en                                     Great products   \n",
       "3   en  I can see the difference in my skin. My skin u...   \n",
       "4   en  I can only say that the product is good but no...   \n",
       "\n",
       "                                               clean  \\\n",
       "0                            sach a good serums. . .   \n",
       "1                                   it s really good   \n",
       "2                                     great products   \n",
       "3  i can see the difference in my skin. my skin u...   \n",
       "4  i can only say that the product is good but no...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0                            [sach, a, good, serums]   \n",
       "1                              [it, s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [i, can, see, the, difference, in, my, skin, m...   \n",
       "4  [i, can, only, say, that, the, product, is, go...   \n",
       "\n",
       "                                       tokens_nostop  \\\n",
       "0                               [sach, good, serums]   \n",
       "1                                  [s, really, good]   \n",
       "2                                  [great, products]   \n",
       "3  [see, difference, skin, skin, used, dull, has,...   \n",
       "4   [say, product, good, good, enough, individually]   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0                                [sach, good, serum]   \n",
       "1                                  [s, realli, good]   \n",
       "2                                   [great, product]   \n",
       "3  [see, differ, skin, skin, use, dull, ha, chang...   \n",
       "4       [say, product, good, good, enough, individu]   \n",
       "\n",
       "                                                 pos         entities  \\\n",
       "0  [(sach, VERB), (a, DET), (good, ADJ), (serums,...               []   \n",
       "1  [(it, PRON), (s, VERB), (really, ADV), (good, ...               []   \n",
       "2                   [(great, ADJ), (products, NOUN)]               []   \n",
       "3  [(i, PRON), (can, AUX), (see, VERB), (the, DET...  [(3, CARDINAL)]   \n",
       "4  [(i, PRON), (can, AUX), (only, ADV), (say, VER...               []   \n",
       "\n",
       "   sentiment  \n",
       "0        3.0  \n",
       "1        3.0  \n",
       "2        3.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install afinn --quiet\n",
    "\n",
    "from afinn import Afinn\n",
    "af = Afinn()\n",
    "\n",
    "df[\"sentiment\"] = df[\"clean\"].map(lambda s: af.score(str(s)))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4b97603-edb7-4705-9dbb-aa761157714d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cosine affinity cannot be used when X contains zero vectors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m n_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m      7\u001b[0m clust \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(\n\u001b[0;32m      8\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[0;32m      9\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     linkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m clust\u001b[38;5;241m.\u001b[39mfit_predict(X_dense)\n\u001b[0;32m     14\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1114\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \n\u001b[0;32m   1096\u001b[0m \u001b[38;5;124;03m    In addition to fitting, this method also return the result of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_predict(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:719\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m--> 719\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:989\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \n\u001b[0;32m    973\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03m    Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    988\u001b[0m X \u001b[38;5;241m=\u001b[39m validate_data(\u001b[38;5;28mself\u001b[39m, X, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1061\u001b[0m, in \u001b[0;36mAgglomerativeClustering._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1057\u001b[0m distance_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_threshold\n\u001b[0;32m   1059\u001b[0m return_distance \u001b[38;5;241m=\u001b[39m (distance_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_distances\n\u001b[1;32m-> 1061\u001b[0m out \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(tree_builder)(\n\u001b[0;32m   1062\u001b[0m     X,\n\u001b[0;32m   1063\u001b[0m     connectivity\u001b[38;5;241m=\u001b[39mconnectivity,\n\u001b[0;32m   1064\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[0;32m   1065\u001b[0m     return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1067\u001b[0m )\n\u001b[0;32m   1068\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_connected_components_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_leaves_, parents) \u001b[38;5;241m=\u001b[39m out[\n\u001b[0;32m   1069\u001b[0m     :\u001b[38;5;241m4\u001b[39m\n\u001b[0;32m   1070\u001b[0m ]\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:714\u001b[0m, in \u001b[0;36m_average_linkage\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_average_linkage\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    713\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinkage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m linkage_tree(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:532\u001b[0m, in \u001b[0;36mlinkage_tree\u001b[1;34m(X, connectivity, n_clusters, linkage, affinity, return_distance)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown linkage option, linkage should be one of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m was given\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;241m%\u001b[39m (linkage_choices\u001b[38;5;241m.\u001b[39mkeys(), linkage)\n\u001b[0;32m    529\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m affinity \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39many(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCosine affinity cannot be used when X contains zero vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connectivity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hierarchy  \u001b[38;5;66;03m# imports PIL\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cosine affinity cannot be used when X contains zero vectors"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_dense = X_tfidf.toarray()\n",
    "\n",
    "n_clusters = min(5, max(2, len(df)//100))\n",
    "\n",
    "clust = AgglomerativeClustering(\n",
    "    n_clusters=n_clusters,\n",
    "    metric=\"cosine\",\n",
    "    linkage=\"average\"\n",
    ")\n",
    "\n",
    "df[\"cluster\"] = clust.fit_predict(X_dense)\n",
    "df[\"cluster\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673e95f8-426a-4c7d-b6cb-f89126928802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "V = normalize(X_dense)\n",
    "\n",
    "representatives = []\n",
    "\n",
    "for c in sorted(df[\"cluster\"].unique()):\n",
    "    idx = df.index[df[\"cluster\"] == c].tolist()\n",
    "    centroid = V[idx].mean(axis=0)\n",
    "    sims = V[idx] @ centroid\n",
    "    rep_index = idx[np.argmax(sims)]\n",
    "    representatives.append((c, df.loc[rep_index,\"clean\"]))\n",
    "\n",
    "representatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235aebf-1fb3-46ef-b18d-d064d71de713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_processed_reviews.csv\", index=False)\n",
    "print(\"‚úÖ final_processed_reviews.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcab9a-b9f7-49ae-bb90-313bf1a50914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0f0b-694c-4812-a1a5-a5fc1fe77af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b11c00-d396-46bb-a11c-0a751e3bee4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e41abb-af70-49a8-a6b9-0d50b616639f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8597da-a921-423b-9003-7d0abed62515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02643c07-2bde-4409-a09f-5bb45bad89e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f899a-d9af-483f-b1f0-486f91c86c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e231c-5044-4d74-8492-36acaf0b79fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6f883-465f-4455-b2a3-a37368298ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96efe69-fe88-4cd1-99f7-c89ed09b395d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa8be8-35e1-4fb9-954f-b8fcb366dc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b66a6a5-9913-4f0c-807a-d72dc9024462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752e2c6-68fa-4c0f-a2f5-effc3bfd1489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6cc18-4bcc-4fec-9e39-3d1a17083f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882ad40-b940-4935-8acd-089d656ea324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd605ef-988a-4b6c-8db9-1b01ceca8265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d2b20-aeed-45f9-8d4a-9580e89bf251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfd5b4-4dca-4d5f-9cdc-5408bd6ee85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389d3be-71a6-4772-9f78-9cda7a7bbb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1ab6d-c14f-4f63-bf61-57d36ac34802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbb512-8c32-4b61-b361-0f55f95d64bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b03b6-3c21-47c2-aeba-0af3c2b7fff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677352b5-acd4-442f-8980-e312bb736e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29a32e-58e5-4610-9633-0080b491a747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b41e58a-ccd2-4577-a44a-e897f094697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89cbb8-3d20-441e-b192-a1096689bdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8712c-a06a-4944-b438-6344b2dfdde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30093fb8-b71b-42be-8759-0213da8dcbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3bc49-2873-4d0c-94de-178e653d8058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4612989-a60d-47d9-ad45-68717c987bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64e2ff-f6b4-47f8-9061-1372d97d7bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fb070-7c29-42b1-b4f3-472888dd77f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae37e5f-a2bc-4d3e-a7f9-ac03e0bc865c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45389f93-ed2f-4759-ae5e-351099f07e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcfd10-9ccd-4072-b51f-94d3214ec3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7793931-139e-4ac0-b4df-8d5ff3995d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac5d21-768f-4f92-a8e7-fead1b19a22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeee6e7-13bb-4b18-b167-88d326c8023a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b8e1f-585d-464b-8957-c4644b53be95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5804ce-3adc-4e8e-b8df-2be2fe5aab75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09d368-14a1-487f-93f0-8128d2d511c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f7fe4-22e5-46f5-afa0-4113bd4e1377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025888b1-871b-4d10-98ce-0e9235581fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccf885-285e-4121-9328-95010bed647f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ebae9-8abf-45de-9ce1-a4ecaeaa9a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e6268-073a-4176-9b77-4dfa97e12deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca757f44-6c8d-4f24-9ce1-51f7c23b696e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f848b-f347-4719-811e-6161dfd054d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dca0e0-72c0-43c6-a06e-b6ceb9c02935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59163d2a-c312-4e77-8e70-29cd57211492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34328d66-d064-4cf7-8b1e-7eb5eb21c1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176b428-03a3-462e-a83e-1b4b2dfe4756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8ece9-59a0-435f-af42-72e324d4495c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fff5a-0c9e-427d-9446-77975ea916bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8981916-e0f4-4077-b01d-ace59b6f0549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53469380-674e-4b9e-8b1a-603dc9c43961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30399aa7-d852-4809-be3e-db12a4dd539a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfa407-3f07-4bab-8e88-22c87c9848c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831250c-b808-4f57-aa0a-88e780d4d63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4428f-7264-45a9-b459-d73815f09e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fa108-6434-4086-8407-7260fd2a33c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717bf7e8-adca-4003-a0ff-231c8ba7f339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112c56d-ad35-4346-a5b6-01910a7b6d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b4bd4-8eda-405c-9a1d-559986230108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b24139-3b02-4b6c-b1cc-f031b225ea02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
